{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is an example of text classification. In this notebook, I go through a step by step process to build a deep learning model(BiLSTM) using Keras library in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anshul.jain/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  if sys.path[0] == '':\n",
      "/home/anshul.jain/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "# loading general libraries\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords \n",
    "set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# loading keras libraries\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Input\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,f1_score,precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.models import Model\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14452/14452 [00:02<00:00, 5915.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of final dataset:\n",
      "(14452, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#loading the data set and doing some cleaning and transformations\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "remove_num = re.compile('[0-9]')\n",
    "\n",
    "def clean_text(text):\n",
    "    try:\n",
    "        text = text.lower()\n",
    "        text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "        text = BAD_SYMBOLS_RE.sub(' ', text)\n",
    "        text = remove_num.sub(' ',text)\n",
    "        word_tokens = word_tokenize(text)\n",
    "        filtered_sentence = [w for w in word_tokens]# if not w in stop_words]\n",
    "        text = ' '.join(word for word in filtered_sentence)\n",
    "        text = text.replace(' p ',' ')\n",
    "\n",
    "        return text\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "df_final = pd.read_csv('Usecase3_Dataset.csv')\n",
    "df_final = df_final.drop_duplicates()\n",
    "df_final['final_text'] = df_final['text'].progress_apply(clean_text)\n",
    "target_names = sorted(list(set(df_final.airline_sentiment)))\n",
    "print('shape of final dataset:')\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot of count of different classes\n",
    "\n",
    "df_final['airline_sentiment'].value_counts().plot(kind = 'bar', figsize=(14, 6));\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of count for different classes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First I do a basic sentiment analysis exercise using the library Vader in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14452/14452 [00:03<00:00, 3933.41it/s]\n",
      "100%|██████████| 14452/14452 [00:00<00:00, 737879.72it/s]\n"
     ]
    }
   ],
   "source": [
    "def classify_score(x):\n",
    "    if x < 0:\n",
    "        return \"negative\"\n",
    "    elif x == 0:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "df_final['scores'] = df_final['text'].progress_apply(lambda x: sid.polarity_scores(x))\n",
    "df_final['compound']  = df_final['scores'].progress_apply(lambda x: x['compound'])\n",
    "df_final['vader_sentiment'] = df_final['compound'].apply(classify_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.50      0.65      9087\n",
      "     neutral       0.40      0.42      0.41      3067\n",
      "    positive       0.33      0.87      0.48      2298\n",
      "\n",
      "    accuracy                           0.54     14452\n",
      "   macro avg       0.54      0.60      0.51     14452\n",
      "weighted avg       0.70      0.54      0.57     14452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report of analysis using Vader\n",
    "\n",
    "y = pd.get_dummies(df_final['airline_sentiment']).values\n",
    "yy = np.argmax(y, axis=1)\n",
    "y_pred = pd.get_dummies(df_final['vader_sentiment']).values\n",
    "y_pred_index = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(yy, y_pred_index,target_names = target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vader here manages to give an F1 score of 0.54 which is not very high. So I decided to try a bi-LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data by converting to numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (14452, 3)\n",
      "Shape of training set: 10116\n",
      "Shape of test set: 4336\n"
     ]
    }
   ],
   "source": [
    "#train_test_split,converting text to numerical content\n",
    "\n",
    "tokenizer_obj = Tokenizer()\n",
    "\n",
    "X = df_final['final_text'].values\n",
    "y = pd.get_dummies(df_final['airline_sentiment']).values\n",
    "print('Shape of label tensor:', y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y)\n",
    "print('Shape of training set:', len(y_train))\n",
    "print('Shape of test set:', len(y_test))\n",
    "\n",
    "total_content = df_final['final_text'].values\n",
    "\n",
    "tokenizer_obj.fit_on_texts(total_content)\n",
    "\n",
    "# pad sequences\n",
    "\n",
    "max_length = max([len(s.split()) for s in total_content])\n",
    "\n",
    "# define vocabulary size \n",
    "\n",
    "vocab_size = len(tokenizer_obj.word_index)+1\n",
    "\n",
    "X_train_tokens = tokenizer_obj.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer_obj.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_tokens,maxlen=max_length,padding='post')\n",
    "X_test_pad = pad_sequences(X_test_tokens,maxlen=max_length,padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I use BiLSTM because it has the advantage of reading the text from start to end as well as other way round. Further it's gated structure helps in remembering key information even further away from current word in the sequence. \n",
    "\n",
    "## configuration of main model,loss function is categorical_crossentropy for multiclass classification, final activation function is softmax, metric is accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main model\n",
    "\n",
    "input = Input(shape=(max_length,))\n",
    "model = Embedding(vocab_size,300,input_length=max_length)(input)\n",
    "model = Bidirectional (LSTM (300,return_sequences=True,dropout=0.5),merge_mode='concat')(model)\n",
    "model = TimeDistributed(Dense(300,activation='relu'))(model)\n",
    "model = Flatten()(model)\n",
    "\n",
    "model = Dense(300,activation='relu')(model)\n",
    "model = Dense(200,activation='relu')(model)\n",
    "model = Dense(100,activation='relu')(model)\n",
    "model = Dense(50,activation='relu')(model)\n",
    "model = Dense(25,activation='relu')(model)\n",
    "output = Dense(3,activation='softmax')(model)\n",
    "\n",
    "model = Model(input,output)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10116 samples\n",
      "Epoch 1/10\n",
      "10116/10116 [==============================] - 48s 5ms/sample - loss: 0.6742 - accuracy: 0.7077\n",
      "Epoch 2/10\n",
      "10116/10116 [==============================] - 47s 5ms/sample - loss: 0.4657 - accuracy: 0.8190\n",
      "Epoch 3/10\n",
      "10116/10116 [==============================] - 48s 5ms/sample - loss: 0.3344 - accuracy: 0.8723\n",
      "Epoch 4/10\n",
      "10116/10116 [==============================] - 49s 5ms/sample - loss: 0.2375 - accuracy: 0.9138\n",
      "Epoch 5/10\n",
      "10116/10116 [==============================] - 48s 5ms/sample - loss: 0.1763 - accuracy: 0.9325\n",
      "Epoch 6/10\n",
      "10116/10116 [==============================] - 47s 5ms/sample - loss: 0.1349 - accuracy: 0.9529\n",
      "Epoch 7/10\n",
      "10116/10116 [==============================] - 47s 5ms/sample - loss: 0.1131 - accuracy: 0.9591\n",
      "Epoch 8/10\n",
      "10116/10116 [==============================] - 46s 5ms/sample - loss: 0.0934 - accuracy: 0.9684\n",
      "Epoch 9/10\n",
      "10116/10116 [==============================] - 47s 5ms/sample - loss: 0.0729 - accuracy: 0.9768\n",
      "Epoch 10/10\n",
      "10116/10116 [==============================] - 47s 5ms/sample - loss: 0.0687 - accuracy: 0.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0858209160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad,y_train, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/anshul.jain/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.89      0.86      2726\n",
      "     neutral       0.61      0.51      0.56       920\n",
      "    positive       0.69      0.66      0.67       690\n",
      "\n",
      "    accuracy                           0.77      4336\n",
      "   macro avg       0.71      0.69      0.70      4336\n",
      "weighted avg       0.76      0.77      0.76      4336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction on test data\n",
    "\n",
    "yy = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict(X_test_pad)\n",
    "print(classification_report(yy, np.argmax(y_pred, axis=1),target_names = target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model built here manages to give an F1 score of 0.77 on the test dataset. It is much better than what we got with Vader. Having said that, the F1 score is not very high but it is most likely the best possible with the given dataset, since this is a pretty efficient model for text classification. A K-fold cross validation on different parts of the data set might give slightly variable F1 score though.\n",
    "\n",
    "## In order to get higher accuracy, either we need more data or we need to use transfer learning techniques such as BERT, etc that can use more relevant embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theme/topic modelling of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some additional libraries\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning functions\n",
    "\n",
    "def remove_links(tweet):\n",
    "    '''Takes a string and removes web links from it'''\n",
    "    tweet = re.sub(r'http\\S+', '', tweet) # remove http links\n",
    "    tweet = re.sub(r'bit.ly/\\S+', '', tweet) # remove bitly links\n",
    "    tweet = tweet.strip('[link]') # remove [links]\n",
    "    return tweet\n",
    "\n",
    "def remove_users(tweet):\n",
    "    '''Takes a string and removes retweet and @user information'''\n",
    "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove retweet\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', tweet) # remove tweeted at\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@'\n",
    "\n",
    "# cleaning function\n",
    "\n",
    "def clean_tweet(tweet, bigrams=False):\n",
    "    tweet = remove_users(tweet)\n",
    "    tweet = remove_links(tweet)\n",
    "    tweet = tweet.lower() # lower case\n",
    "    tweet = re.sub('['+my_punctuation + ']+', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub('\\s+', ' ', tweet) #remove double spacing\n",
    "    tweet = re.sub('([0-9]+)', '', tweet) # remove numbers\n",
    "    tweet_token_list = [word for word in tweet.split(' ')\n",
    "                            if word not in my_stopwords] # remove stopwords\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14452/14452 [00:00<00:00, 16279.65it/s]\n"
     ]
    }
   ],
   "source": [
    "df_final['clean_tweet'] = df_final['text'].progress_apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the vectorizer object will be used to transform text to vector form\n",
    "vectorizer = CountVectorizer(max_df=0.8, min_df=100, token_pattern='\\w+|\\$[\\d\\.]+|\\S+')\n",
    "\n",
    "# apply transformation\n",
    "tf = vectorizer.fit_transform(df_final['clean_tweet']).toarray()\n",
    "\n",
    "# tf_feature_names tells us what word each column in the matrix represents\n",
    "tf_feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_topics = 5\n",
    "model = LatentDirichletAllocation(n_components=number_of_topics, random_state=0)\n",
    "model.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0 words</th>\n",
       "      <th>Topic 0 weights</th>\n",
       "      <th>Topic 1 words</th>\n",
       "      <th>Topic 1 weights</th>\n",
       "      <th>Topic 2 words</th>\n",
       "      <th>Topic 2 weights</th>\n",
       "      <th>Topic 3 words</th>\n",
       "      <th>Topic 3 weights</th>\n",
       "      <th>Topic 4 words</th>\n",
       "      <th>Topic 4 weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flight</td>\n",
       "      <td>3826.2</td>\n",
       "      <td>service</td>\n",
       "      <td>958.2</td>\n",
       "      <td>thanks</td>\n",
       "      <td>1039.7</td>\n",
       "      <td>thank</td>\n",
       "      <td>583.2</td>\n",
       "      <td>flights</td>\n",
       "      <td>386.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cancelled</td>\n",
       "      <td>1038.2</td>\n",
       "      <td>customer</td>\n",
       "      <td>748.2</td>\n",
       "      <td>back</td>\n",
       "      <td>496.6</td>\n",
       "      <td>would</td>\n",
       "      <td>443.7</td>\n",
       "      <td>airline</td>\n",
       "      <td>384.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>delayed</td>\n",
       "      <td>529.9</td>\n",
       "      <td>hold</td>\n",
       "      <td>535.0</td>\n",
       "      <td>get</td>\n",
       "      <td>423.1</td>\n",
       "      <td>like</td>\n",
       "      <td>425.5</td>\n",
       "      <td>fly</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plane</td>\n",
       "      <td>508.2</td>\n",
       "      <td>phone</td>\n",
       "      <td>426.0</td>\n",
       "      <td>please</td>\n",
       "      <td>329.6</td>\n",
       "      <td>bag</td>\n",
       "      <td>376.2</td>\n",
       "      <td>way</td>\n",
       "      <td>291.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flightled</td>\n",
       "      <td>499.2</td>\n",
       "      <td>call</td>\n",
       "      <td>370.8</td>\n",
       "      <td>home</td>\n",
       "      <td>287.6</td>\n",
       "      <td>guys</td>\n",
       "      <td>364.0</td>\n",
       "      <td>want</td>\n",
       "      <td>264.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get</td>\n",
       "      <td>361.9</td>\n",
       "      <td>help</td>\n",
       "      <td>363.8</td>\n",
       "      <td>hours</td>\n",
       "      <td>272.4</td>\n",
       "      <td>know</td>\n",
       "      <td>355.2</td>\n",
       "      <td>ticket</td>\n",
       "      <td>249.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic 0 words Topic 0 weights Topic 1 words Topic 1 weights Topic 2 words  \\\n",
       "0  flight        3826.2          service       958.2           thanks         \n",
       "1  cancelled     1038.2          customer      748.2           back           \n",
       "2  delayed       529.9           hold          535.0           get            \n",
       "3  plane         508.2           phone         426.0           please         \n",
       "4  flightled     499.2           call          370.8           home           \n",
       "5  get           361.9           help          363.8           hours          \n",
       "\n",
       "  Topic 2 weights Topic 3 words Topic 3 weights Topic 4 words Topic 4 weights  \n",
       "0  1039.7          thank         583.2           flights       386.9           \n",
       "1  496.6           would         443.7           airline       384.3           \n",
       "2  423.1           like          425.5           fly           375.0           \n",
       "3  329.6           bag           376.2           way           291.2           \n",
       "4  287.6           guys          364.0           want          264.9           \n",
       "5  272.4           know          355.2           ticket        249.7           "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)\n",
    "\n",
    "no_top_words = 6\n",
    "display_topics(model, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I tried to model the topic of the tweets using 6 topics. From the table above, it is clear that some of the tweets are about:\n",
    "#### 1) cancellation or delay of flights \n",
    "#### 2) seeking customer service help\n",
    "#### 3) other flight related issues such as bag, or seeking ticket or expressing gratitude"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
